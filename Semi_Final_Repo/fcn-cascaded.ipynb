{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport librosa\nimport librosa.display\nimport numpy as np\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport tensorflow as tf\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:08:05.309280Z","iopub.execute_input":"2022-04-05T11:08:05.310386Z","iopub.status.idle":"2022-04-05T11:08:13.935159Z","shell.execute_reply.started":"2022-04-05T11:08:05.310245Z","shell.execute_reply":"2022-04-05T11:08:13.933827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata_file = '../input/weeklyforecasting/train_data.csv'\n#metadata_file_unseen = ''\ndf = pd.read_csv(metadata_file)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:08:36.846803Z","iopub.execute_input":"2022-04-05T11:08:36.847197Z","iopub.status.idle":"2022-04-05T11:08:37.204312Z","shell.execute_reply.started":"2022-04-05T11:08:36.847154Z","shell.execute_reply":"2022-04-05T11:08:37.203151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df2 = pd.read_csv(metadata_file_unseen)\n#df2.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final_df = pd.concat([df,df2],ignore_index=True)\n#final_df = final_df.sample(frac=1).reset_index(drop=True)\nfinal_df = df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df.to_csv(\"hee.csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df['DailySales'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\ndict_results = {}\n\nlist_test = [3427,7666,9925, 20824,23569,32245,35449,35530,35584,37861,38518,42496,43630,43738,48940,52099,57058,59749,65788,75886,86974,86992,87046,87559,88450,117610,119554,130993,142756,145330,145978,172033,172582,210868,213802,216151,225259,267478,267496,371104,371239,399220,416212,731104,745945,815101,836152,838456,858886,865933,893824,913561,999403,1003147,1003192,1006009,1006099,1006108,1010068,1015621,1024810,1026871,1032550,1032559,1032568,1044502,1044619,1044682,1047130,1048975,1049776,1054978,1056463,1060630,1060909,1063600,1064473,1064572,1067074,1067092,1067119,1067128,1068883,1071115,1071124,1075651,1076929,1077118,1081060,1081078,1081339,1084498,1090024,1092184,1097143,1101553,1103056,1105018]\n\nprint(Counter(list_test))\n\nlist_new = [3418]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_test = {}\nfrom sklearn.preprocessing import MinMaxScaler\nfor item in list_test:\n    print(item)\n    index = list_test.index(item)\n    Item_3148_train_dataset = train_dataset.loc[train_dataset['ItemCode'] == item]\n    Item_3148_train_dataset.sort_values(by='DateID', inplace=True)\n    Item_3148_train_dataset_forTraining = Item_3148_train_dataset[['DateID', 'DailySales']]\n    Item_3148_train_dataset_forTraining.head()\n    Item_3148_numpy = Item_3148_train_dataset_forTraining.to_numpy()\n    length = len(Item_3148_train_dataset_forTraining)\n    Item_3148_train_dataset_forTraining.index = range(length)\n    Item_3148_series = Item_3148_train_dataset_forTraining[\"DailySales\"].squeeze()\n    print(\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(extracted_features)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nrandom.shuffle(extracted_features)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_features_df=pd.DataFrame(extracted_features,columns=['PredictedValue','Type','Price','DisValue','Days','Real'])\nextracted_features_df.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=np.array(extracted_features_df['PredictedValue','Type','Price','DisValue','Days'].tolist())\ny=np.array(extracted_features_df['Real'].tolist())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:21:32.847226Z","iopub.execute_input":"2022-04-05T11:21:32.847622Z","iopub.status.idle":"2022-04-05T11:21:34.053342Z","shell.execute_reply.started":"2022-04-05T11:21:32.847586Z","shell.execute_reply":"2022-04-05T11:21:34.052396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\n###first layer\nmodel.add(Dense(100,input_shape=(40,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n###second layer\nmodel.add(Dense(200))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n###third layer\nmodel.add(Dense(100))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\n###final layer\nmodel.add(Dense(6))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:21:36.635689Z","iopub.execute_input":"2022-04-05T11:21:36.635983Z","iopub.status.idle":"2022-04-05T11:21:36.816612Z","shell.execute_reply.started":"2022-04-05T11:21:36.635955Z","shell.execute_reply":"2022-04-05T11:21:36.815047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:21:47.147453Z","iopub.execute_input":"2022-04-05T11:21:47.147767Z","iopub.status.idle":"2022-04-05T11:21:47.167117Z","shell.execute_reply.started":"2022-04-05T11:21:47.147736Z","shell.execute_reply":"2022-04-05T11:21:47.165956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nfrom datetime import datetime \n\nnum_epochs = 200\nnum_batch_size = 32\n\ncheckpointer = ModelCheckpoint(filepath='saved_models/audio_classification_2.hdf5', verbose=1, save_best_only=True)  \n#no num - first attempt with 6000 samples withoit truncating 40 mfcc - best / no dropout layers\n#1 - 1s truncated 20 mfcc\n#2 - 1s truncated with 22050Hz 40 mfcc\n\n\nstart = datetime.now()\n\nhistory = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n#  \"Accuracy\"\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# \"Loss\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\n#  \"Accuracy\"\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# \"Loss\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}